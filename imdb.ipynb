{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4f6962",
   "metadata": {},
   "source": [
    "Binary classification using Deep Neural Networks Example: Classify movie reviews into\n",
    "positive reviews and negative reviews, just based on the text content of the reviews.\n",
    "Use IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa5bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6024 - loss: 0.6593 - val_accuracy: 0.7990 - val_loss: 0.4343\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8593 - loss: 0.3434 - val_accuracy: 0.8482 - val_loss: 0.3398\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8958 - loss: 0.2613 - val_accuracy: 0.8585 - val_loss: 0.3210\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9251 - loss: 0.2004 - val_accuracy: 0.8683 - val_loss: 0.3205\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9360 - loss: 0.1807 - val_accuracy: 0.8763 - val_loss: 0.3316\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.3277\n",
      "Accuracy: 0.8714\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AE15723D90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Predicted: Negative | Actual: Negative\n",
      "Predicted: Positive | Actual: Positive\n",
      "Predicted: Positive | Actual: Negative\n",
      "Predicted: Negative | Actual: Positive\n",
      "Predicted: Positive | Actual: Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"imdb_master.csv\", on_bad_lines='skip', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 1: Filter only training rows with 'pos' or 'neg' labels\n",
    "df = df.query(\"type == 'train' and label in ['pos', 'neg']\")\n",
    "\n",
    "# Step 2: Remove HTML tags from reviews\n",
    "df['review'] = df['review'].str.replace('<.*?>', '', regex=True)\n",
    "\n",
    "# Prepare data\n",
    "texts = df['review']\n",
    "labels = LabelEncoder().fit_transform(df['label'])\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "X = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(X, maxlen=200)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=200),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy[1]:.4f}\")\n",
    "\n",
    "# Predict\n",
    "predictions = (model.predict(X_test[:5]) > 0.5).astype(int)\n",
    "\n",
    "# Display results\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {'Positive' if predictions[i] == 1 else 'Negative'} | Actual: {'Positive' if y_test[i] == 1 else 'Negative'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
